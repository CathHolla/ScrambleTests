{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving from words to sentences\n",
    "\n",
    "### What is the most basic thing we want to be able to do with more than just word-level information?\n",
    "\n",
    "We propose that natural language inference is a good domain to test for whether relational information between words is being used. Humans are good at it and give predictable answers to these questions, and they require concrete and tangible realtional information between words to get to the right answer.\n",
    "\n",
    "### Datasets that require increasing amounts of non-local information\n",
    "\n",
    "Several tasks now are interested in sentence representations that go beyond bag-of-words. Sentiment analysis and paraphrase datasets go slightly above, but a lot of the performance of most models on these comes from word-level information. While sentence representations do outperform BOW on these, it is unclear exactly where they have improved.\n",
    "\n",
    "Natural language inference is a useful domain in which we can propose challenges that require increasingly complex compositionality and are therefore more diagnostic for what is being learnt and what isn't.\n",
    "\n",
    "We present this set of datasets for natural language inference that humans perform predictably well on, and are impossible to capture from word-level information. \n",
    "\n",
    "### Choosing a vocabulary\n",
    "We chose the SNLI dataset vocabulary, so that we could benchmark on the InferSent model that was trained end-to-end on natural language inference with this dataset. This assumes GloVe word embeddings.\n",
    "\n",
    "NOTE : I haven't actually checked if these examples are within the vocab, but that's easy to do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "id2label = {0:'CONTRADICTION', 1:'NEUTRAL', 2:'ENTAILMENT'}\n",
    "label2id = {'CONTRADICTION': 0, 'NEUTRAL':1, 'ENTAILMENT':2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinds of examples:\n",
    "\n",
    "#### Requiring word-level information regarding its symmetry\n",
    "\n",
    "A. **Symmetric vs non-symmetric verbs (over subject-object):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  1350 \n",
      "\n",
      "the old man holding an umbrella converses with the tall girl . \n",
      "the tall girl converses with the old man holding an umbrella . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the boy in the red shorts ignores the boy . \n",
      "the boy ignores the boy in the red shorts . \n",
      "NEUTRAL\n",
      "\n",
      "\n",
      "the woman in the black shirt is near to the boy . \n",
      "the boy is near to the woman in the black shirt . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the old man holding an umbrella is near to the tall girl . \n",
      "the tall girl is near to the old man holding an umbrella . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the girl carrying a basket meets the girl . \n",
      "the girl meets the girl carrying a basket . \n",
      "ENTAILMENT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insensitive to tense for now (?)\n",
    "\n",
    "v_ents = ['meets', 'resembles', 'is near to', 'is far from', 'converses with']#, 'is beside', 'collides with']\n",
    "v_cons = ['overtakes', 'gives the hat to', 'takes the bag from', 'is behind', 'is in front of']\n",
    "# also 'causes'\n",
    "v_neus = ['watches', 'ignores', 'hits', 'hugs', 'shoves']#, 'admires', 'talks to']\n",
    "\n",
    "# Perhaps I should select from the most commonly used verbs...? And get rid of preposition phrase based ones....? \n",
    "# Overlaps with comparatives slightly otherwise\n",
    "\n",
    "nps = [\"the woman in the black shirt\", \"the boy in the red shorts\", \n",
    "       \"the fat man\", \"the old man holding an umbrella\", \"the tall girl\", \"the old woman\", \n",
    "       \"the man wearing a hat\", \"the girl carrying a basket\", \"the girl\", \"the boy\"]\n",
    "\n",
    "sents_A = []\n",
    "sents_B = []\n",
    "labels = []\n",
    "\n",
    "vs = {\"ENTAILMENT\": v_ents,\n",
    "     \"CONTRADICTION\": v_cons,\n",
    "     \"NEUTRAL\": v_neus}\n",
    "\n",
    "for np1 in nps:\n",
    "    for np2 in nps:\n",
    "        for key in vs:\n",
    "            for v in vs[key]:\n",
    "                if (np1 != np2):\n",
    "                    sents_A.append(np1 + \" \" + v + \" \" + np2 + ' . ')\n",
    "                    sents_B.append(np2 + \" \" + v + \" \" + np1 + ' . ')\n",
    "                    labels.append(key)\n",
    "                    \n",
    "#                     # self-rep\n",
    "#                     sents_A.append(np1 + \" \" + v + \" \" + np2 + ' . ')\n",
    "#                     sents_B.append(np1 + \" \" + v + \" \" + np2 + ' . ')\n",
    "#                     labels.append('ENTAILMENT')\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "open(\"testData/true/s1.verb\", 'w').write(\"\\n\".join([str(x) for x in sents_A]))\n",
    "open(\"testData/true/s2.verb\", 'w').write(\"\\n\".join([str(x) for x in sents_B]))\n",
    "np.savetxt(\"testData/true/labels.verb\", [label2id[x] for x in labels], fmt='%i')\n",
    "\n",
    "print(\"Total: \", len(labels), \"\\n\")\n",
    "\n",
    "N = 5\n",
    "\n",
    "temp = np.random.randint(0, len(labels), N)\n",
    "for i in temp:\n",
    "    print(sents_A[i])\n",
    "    print(sents_B[i])\n",
    "    print(labels[i])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "#FUTURE\n",
    "# Give people on Mturk a noun phrase + verb and ask them to fill it out with a phrase\n",
    "# such that the converse makes sense (for asym_v's)\n",
    "# We ca nbootstrap noun phrases that people give us for more sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. **Temporal ordering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  2400 \n",
      "\n",
      "the old man holding an umbrella sat down while the thin woman shouted loudly . \n",
      "the thin woman shouted loudly while the old man holding an umbrella sat down . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the fat man walked in as the old man holding an umbrella frowned angrily . \n",
      "the old man holding an umbrella frowned angrily as the fat man walked in . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the old man holding an umbrella frowned angrily before the thin woman sat down . \n",
      "the thin woman sat down before the old man holding an umbrella frowned angrily . \n",
      "CONTRADICTION\n",
      "\n",
      "\n",
      "the thin woman sat down while the woman in the black shirt walked in . \n",
      "the woman in the black shirt walked in while the thin woman sat down . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the woman in the black shirt shouted loudly as the fat man walked in . \n",
      "the fat man walked in as the woman in the black shirt shouted loudly . \n",
      "ENTAILMENT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tws = [\"after\", \"before\", \"while\", \"as\"]\n",
    "infs = [\"CONTRADICTION\", \"CONTRADICTION\", \"ENTAILMENT\", \"ENTAILMENT\"]\n",
    "# vps = ['sat down', 'walked in', 'stood up']\n",
    "# nps = [\"the woman in the black shirt\", \"the boy in the red shorts\", \n",
    "#        \"the smiling man\"]\n",
    "vps = ['sat down', 'walked in', 'stood up', 'shouted loudly', 'frowned angrily']\n",
    "nps = [\"the woman in the black shirt\",\n",
    "       \"the fat man\", \"the old man holding an umbrella\", \n",
    "       \"the thin woman\",\"the girl\", \"the boy\"]\n",
    "\n",
    "sents_A = []\n",
    "sents_B = []\n",
    "labels = []\n",
    "\n",
    "for vp1 in vps:\n",
    "    for vp2 in vps:\n",
    "        for np1 in nps:\n",
    "            for np2 in nps:\n",
    "                for w, inf in zip(tws, infs):\n",
    "                    if ((np1 != np2) & (vp1 != vp2)):\n",
    "                        sents_A.append(np1 + \" \" + vp1 + \" \" + w + \" \" + np2 + ' ' + vp2 + ' . ')\n",
    "                        sents_B.append(np2 + \" \" + vp2 + \" \" + w + \" \" + np1 + ' ' + vp1 + ' . ')\n",
    "                        labels.append(inf)\n",
    "                        \n",
    "#                         # equalize numbers of each type\n",
    "#                         u = np.random.uniform()\n",
    "#                         if (u > 0.5):\n",
    "#                             sents_A.append(np1 + \" \" + vp1 + \" \" + w + \" \" + np2 + ' ' + vp2 + ' . ')\n",
    "#                             sents_B.append(np2 + \" \" + vp1 + \" \" + w + \" \" + np1 + ' ' + vp2 + ' . ')\n",
    "#                             labels.append(\"NEUTRAL\")\n",
    "                \n",
    "#                 # self-rep\n",
    "#                 sents_A.append(np1 + \" \" + w + \" \" + np2 + ' . ')\n",
    "#                 sents_B.append(np1 + \" \" + w + \" \" + np2 + ' . ')\n",
    "#                 labels.append('ENTAILMENT')\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "open(\"testData/true/s1.temp\", 'w').write(\"\\n\".join([str(x) for x in sents_A]))\n",
    "open(\"testData/true/s2.temp\", 'w').write(\"\\n\".join([str(x) for x in sents_B]))\n",
    "np.savetxt(\"testData/true/labels.temp\", [label2id[x] for x in labels])\n",
    "\n",
    "print(\"Total: \", len(labels), \"\\n\")\n",
    "\n",
    "N = 5\n",
    "temp = np.random.randint(0, len(labels), N)\n",
    "for i in temp:\n",
    "    print(sents_A[i])\n",
    "    print(sents_B[i])\n",
    "    print(labels[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# FUTURE\n",
    "# Give people on Mturk a noun phrase + \"after\" and ask them to fill it out, \n",
    "# permute order and include with \"before, as and while\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requiring bi-gram compositionality\n",
    "\n",
    "A. Modifiers (adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  4800 \n",
      "\n",
      "The woman in the black shirt who is happy, collides with the boy who is sad . \n",
      "The woman in the black shirt who is sad, collides with the boy . \n",
      "CONTRADICTION\n",
      "\n",
      "\n",
      "The boy who is big, hugs the man wearing a suit who is small . \n",
      "The boy, hugs the man wearing a suit who is small . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "The woman in the black shirt who is big, hits the girl who is small . \n",
      "The woman in the black shirt, hits the girl who is small . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "The man wearing a suit who is tall, shoves the boy who is short . \n",
      "The man wearing a suit who is short, shoves the boy . \n",
      "CONTRADICTION\n",
      "\n",
      "\n",
      "The old man holding an umbrella who is happy, ignores the girl who is sad . \n",
      "The old man holding an umbrella who is sad, ignores the girl . \n",
      "CONTRADICTION\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vps = ['meets', 'resembles', 'watches', 'ignores', 'hits', 'hugs', 'shoves', 'admires', 'talks to', 'collides with']\n",
    "# vps = ['meets', 'resembles', 'watches', 'ignores', 'hits']\n",
    "\n",
    "adjs_temp = {'pos': ['tall', 'cheerful', 'big', 'fat', 'clean', 'happy'],\n",
    "          'neg': ['short', 'grumpy', 'small', 'thin', 'dirty', 'sad']}\n",
    "# adjs = {'pos': ['tall', 'big', 'fat'],\n",
    "#           'neg': ['short', 'small', 'thin']}\n",
    "\n",
    "adjs = {}\n",
    "adjs['pos'] = adjs_temp['pos'] + adjs_temp['neg']\n",
    "adjs['neg'] = adjs_temp['neg'] + adjs_temp['pos']\n",
    "\n",
    "nps = [\"woman in the black shirt\",\n",
    "       \"man wearing a suit\", \"old man holding an umbrella\",\n",
    "       \"girl\", \"boy\"]\n",
    "\n",
    "\n",
    "sents_A = []\n",
    "sents_B = []\n",
    "labels = []\n",
    "\n",
    "for vp in vps:\n",
    "    for np1 in nps:\n",
    "        for np2 in nps:\n",
    "            if (np1 != np2):\n",
    "                for p, n in zip(adjs['pos'], adjs['neg']):\n",
    "                    \n",
    "                    sents_A.append('The ' +  np1 + ' who is ' + p + ', ' + vp + ' the ' + np2 + ' who is ' + n + ' . ')\n",
    "                    sents_B.append('The ' +  np1 + ', ' + vp + ' the ' + np2 + ' who is ' + n + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "                    \n",
    "                    sents_A.append('The ' +  np1 + ' who is ' + p + ', ' + vp + ' the ' + np2 + ' who is ' + n + ' . ')\n",
    "                    sents_B.append('The ' + np1 + ' who is ' + n + ', '+ vp + ' the ' + np2 + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                \n",
    "                    \n",
    "        \n",
    "        \n",
    "open(\"testData/true/s1.adjr\", 'w').write(\"\\n\".join([str(x) for x in sents_A]))\n",
    "open(\"testData/true/s2.adjr\", 'w').write(\"\\n\".join([str(x) for x in sents_B]))\n",
    "np.savetxt(\"testData/true/labels.adjr\", [label2id[x] for x in labels], fmt='%i')\n",
    "\n",
    "print(\"Total: \", len(labels), \"\\n\")\n",
    "\n",
    "N = 5\n",
    "temp = np.random.randint(0, len(labels), N)\n",
    "for i in temp:\n",
    "    print(sents_A[i])\n",
    "    print(sents_B[i])\n",
    "    print(labels[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# FUTURE\n",
    "# Find all sentences in s2 from multiNLI that have two non consecutive adjectives in them and swap them, \n",
    "# check with Mturk for label - because they won't be opposites like here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Modifiers that negate - if and only if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  216 \n",
      "\n",
      "it is very cold when the air is damp . \n",
      "When the air is damp, it is very cold . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the roads are dangerous when there are many clouds . \n",
      "When there are many clouds, the roads are dangerous . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the roads are dangerous if there is a lot of snow . \n",
      "the roads are not dangerous if there is a lot of snow . \n",
      "CONTRADICTION\n",
      "\n",
      "\n",
      "it is better to stay home when the air is damp . \n",
      "When the air is damp, it is better to stay home . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the trees do look beautiful when the sun is not shining . \n",
      "When the sun is not shining, the trees do look beautiful . \n",
      "ENTAILMENT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "connec = ['when', 'if']\n",
    "phe = {'pos': ['it rains', 'there is a lot of snow', 'the wind does blow very hard',\n",
    "              'there are many clouds', 'the sun is not shining', 'the air is damp'],\n",
    "      'neg' : ['it does not rain', 'there is not a lot of snow', 'the wind does not blow very hard',\n",
    "              'there are not many clouds', 'the sun is shining', 'the air is not damp']}\n",
    "\n",
    "con = {'pos': ['the trees do look beautiful', 'it is very cold', 'everyone does feel sad',\n",
    "              'the roads are dangerous', 'it is better to stay home', 'the dogs do not go outside'],\n",
    "      'neg' : ['the trees do not look beautiful', 'it is not very cold', 'everyone does not feel sad',\n",
    "              'the roads are not dangerous', 'it is not better to stay home', 'the dogs do go outside']}\n",
    "\n",
    "sents_A = []\n",
    "sents_B = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for conn in connec:\n",
    "    for p_i in np.arange(len(phe['pos'])):\n",
    "        for c_i in np.arange(len(con['pos'])):\n",
    "        \n",
    "            pcon = con['pos'][c_i]\n",
    "            ncon = con['neg'][c_i]\n",
    "        \n",
    "            pphe = phe['pos'][p_i]\n",
    "            nphe = phe['neg'][p_i]\n",
    "        \n",
    "            sents_A.append(pcon + \" \" + conn + \" \" + pphe + ' . ')\n",
    "            sents_B.append(ncon + \" \" + conn + \" \" + pphe + ' . ')\n",
    "            labels.append('CONTRADICTION')\n",
    "        \n",
    "            sents_A.append(pcon + \" \" + conn + \" \" + pphe + ' . ')\n",
    "            sents_B.append(pcon + \" \" + conn + \" \" + nphe + ' . ')\n",
    "            labels.append('NEUTRAL')\n",
    "        \n",
    "            # self-rep/rephrase\n",
    "            sents_A.append(pcon + \" when \" + pphe + ' . ')\n",
    "            sents_B.append('When ' + pphe + ', ' + pcon + ' . ')\n",
    "            labels.append('ENTAILMENT')\n",
    "        \n",
    "    #         # two nots\n",
    "    #         sents_A.append(pcon + \" when \" + pphe + ' . ')\n",
    "    #         sents_B.append(ncon + \" when \" + nphe + ' . ')\n",
    "    #         labels.append('NEUTRAL')\n",
    "        \n",
    "    #         # Rephrase\n",
    "    #         sents_A.append(pcon + \" when \" + pphe + ' . ')\n",
    "    #         sents_B.append(\"When \" + pphe + ' , ' + ncon + ' . ')\n",
    "    #         labels.append('CONTRADICTION')\n",
    "        \n",
    "    #         sents_A.append(pcon + \" when \" + pphe + ' . ')\n",
    "    #         sents_B.append(\"When \" + nphe + ' , ' + pcon + ' . ')\n",
    "    #         labels.append('NEUTRAL')\n",
    "        \n",
    "    \n",
    "\n",
    "open(\"testData/true/s1.ncon\", 'w').write(\"\\n\".join([str(x) for x in sents_A]))\n",
    "open(\"testData/true/s2.ncon\", 'w').write(\"\\n\".join([str(x) for x in sents_B]))\n",
    "np.savetxt(\"testData/true/labels.ncon\", [label2id[x] for x in labels], fmt='%i')\n",
    "\n",
    "print(\"Total: \", len(labels), \"\\n\")\n",
    "\n",
    "N = 5\n",
    "temp = np.random.randint(0, len(labels), N)\n",
    "for i in temp:\n",
    "    print(sents_A[i])\n",
    "    print(sents_B[i])\n",
    "    print(labels[i])\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. With but/however/whereas discourse markers\n",
    "\n",
    "Could also add although?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  5040 \n",
      "\n",
      "the man wearing a hat does frown angrily , whereas the boy does not frown angrily . \n",
      "the man wearing a hat does not frown angrily . \n",
      "CONTRADICTION\n",
      "\n",
      "\n",
      "the girl carrying a basket does not sit down , but the man wearing a hat does sit down . \n",
      "the man wearing a hat does sit down . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the fat man does not walk in , whereas the boy does walk in . \n",
      "the boy does walk in . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the fat man does not frown angrily , however the old man holding an umbrella does frown angrily . \n",
      "the old man holding an umbrella does frown angrily . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the girl does not frown angrily , whereas the woman in the black shirt does frown angrily . \n",
      "the woman in the black shirt does frown angrily . \n",
      "ENTAILMENT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate discourse marked examples\n",
    "discs = ['however', 'but', 'whereas']\n",
    "nps = [\"the woman in the black shirt\",\n",
    "       \"the fat man\", \"the old man holding an umbrella\", \"the girl\", \"the boy\", \n",
    "       \"the man wearing a hat\", \"the girl carrying a basket\"]\n",
    "\n",
    "vps = ['sit down', 'walk in', 'stand up', 'shout loudly', 'frown angrily']\n",
    "\n",
    "sents_A = []\n",
    "sents_B = []\n",
    "labels = []\n",
    "\n",
    "for disc in discs:\n",
    "    for np1 in nps:\n",
    "        for np2 in nps:\n",
    "            if (np1 != np2):\n",
    "                for vp in vps:\n",
    "                    sents_A.append(np1 + \" does \" + vp + \" , \" + disc + \" \" + np2 + ' does not ' + vp + ' . ')\n",
    "                    sents_B.append(np1 + \" does \" + vp + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" does \" + vp + \" , \" + disc + \" \" + np2 + ' does not ' + vp + ' . ')\n",
    "                    sents_B.append(np1 + \" does not \" + vp + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" does \" + vp + \" , \" + disc + \" \" + np2 + ' does not ' + vp + ' . ')\n",
    "                    sents_B.append(np2 + \" does \" + vp + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" does \" + vp + \" , \" + disc + \" \" + np2 + ' does not ' + vp + ' . ')\n",
    "                    sents_B.append(np2 + \" does not \" + vp + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" does not \" + vp + \" , \" + disc + \" \" + np2 + ' does ' + vp + ' . ')\n",
    "                    sents_B.append(np1 + \" does \" + vp + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" does not \" + vp + \" , \" + disc + \" \" + np2 + ' does ' + vp + ' . ')\n",
    "                    sents_B.append(np1 + \" does not \" + vp + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" does not \" + vp + \" , \" + disc + \" \" + np2 + ' does ' + vp + ' . ')\n",
    "                    sents_B.append(np2 + \" does \" + vp + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" does not \" + vp + \" , \" + disc + \" \" + np2 + ' does ' + vp + ' . ')\n",
    "                    sents_B.append(np2 + \" does not \" + vp + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                    \n",
    "                                    \n",
    "\n",
    "\n",
    "\n",
    "open(\"testData/true/s1.subjv\", 'w').write(\"\\n\".join([str(x) for x in sents_A]))\n",
    "open(\"testData/true/s2.subjv\", 'w').write(\"\\n\".join([str(x) for x in sents_B]))\n",
    "np.savetxt(\"testData/true/labels.subjv\", [label2id[x] for x in labels], fmt='%i')\n",
    "\n",
    "print(\"Total: \", len(labels), \"\\n\")\n",
    "\n",
    "N = 5\n",
    "temp = np.random.randint(0, len(labels), N)\n",
    "for i in temp:\n",
    "    print(sents_A[i])\n",
    "    print(sents_B[i])\n",
    "    print(labels[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requiring bigram compositionality as well as symmetry understanding\n",
    "\n",
    "A. Comparatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  1728 \n",
      "\n",
      "the boy is more tired than the man holding an umbrella . \n",
      "the boy is less tired than the man holding an umbrella . \n",
      "CONTRADICTION\n",
      "\n",
      "\n",
      "the green cabinet is heavier than the book case . \n",
      "the green cabinet is heavier than the book case . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the old hat stand is lighter than the book case . \n",
      "the old hat stand is lighter than the book case . \n",
      "ENTAILMENT\n",
      "\n",
      "\n",
      "the girl is less cheerful than the fat man . \n",
      "the girl is more cheerful than the fat man . \n",
      "CONTRADICTION\n",
      "\n",
      "\n",
      "the wooden dresser is bigger than the book case . \n",
      "the wooden dresser is bigger than the book case . \n",
      "ENTAILMENT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# should I do taller and not taller? Or taller and shorter?\n",
    "\n",
    "comps_p = {'pos': ['taller', 'more cheerful', 'more tired', 'better dressed'],\n",
    "          'neg': ['shorter', 'less cheerful', 'less tired', 'not better dressed']}\n",
    "\n",
    "comps_o = {'pos': ['bigger','heavier', 'more expensive'],\n",
    "           'neg' : ['smaller', 'lighter', 'cheaper']}\n",
    "\n",
    "comps_t = {'pos': ['longer'], \n",
    "           'neg': ['shorter']}\n",
    "\n",
    "nps_p = [\"the woman in the black shirt\", \"the boy\", \n",
    "       \"the fat man\", \"the man holding an umbrella\", \"the girl\", \"the old woman\"]\n",
    "nps_o = ['the brown table', 'the metal chair', 'the green cabinet', 'the wooden dresser', \n",
    "         'the book case', 'the old hat stand']\n",
    "nps_t = ['the art film', 'the classical music concert', 'the theatre performance']\n",
    "\n",
    "sents_A = []\n",
    "sents_B = []\n",
    "labels = []\n",
    "\n",
    "nps = {'obj' : nps_o,\n",
    "      'pers': nps_p,\n",
    "      'time': nps_t}\n",
    "\n",
    "comps = {'obj' : comps_o,\n",
    "      'pers': comps_p,\n",
    "      'time': comps_t}\n",
    "\n",
    "for key in nps:\n",
    "    for np1 in nps[key]:\n",
    "        for np2 in nps[key]:\n",
    "            for p, n in zip(comps[key]['pos'], comps[key]['neg']):\n",
    "                if (np1 != np2):\n",
    "                    \n",
    "#                     # words not exactly the same - one word difference\n",
    "                    \n",
    "                    sents_A.append(np1 + \" is \" + p + \" than \" + np2 + ' . ')\n",
    "                    sents_B.append(np2 + \" is \" + n + \" than \" + np1 + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" is \" + n + \" than \" + np2 + ' . ')\n",
    "                    sents_B.append(np2 + \" is \" + p + \" than \" + np1 + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "\n",
    "                    sents_A.append(np1 + \" is \" + p + \" than \" + np2 + ' . ')\n",
    "                    sents_B.append(np1 + \" is \" + n + \" than \" + np2 + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" is \" + n + \" than \" + np2 + ' . ')\n",
    "                    sents_B.append(np1 + \" is \" + p + \" than \" + np2 + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" is \" + p + \" than \" + np2 + ' . ')\n",
    "                    sents_B.append(np2 + \" is \" + p + \" than \" + np1 + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" is \" + n + \" than \" + np2 + ' . ')\n",
    "                    sents_B.append(np2 + \" is \" + n + \" than \" + np1 + ' . ')\n",
    "                    labels.append('CONTRADICTION')\n",
    "                    \n",
    "#                     # Self - rep\n",
    "                    sents_A.append(np1 + \" is \" + p + \" than \" + np2 + ' . ')\n",
    "                    sents_B.append(np1 + \" is \" + p + \" than \" + np2 + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "                    \n",
    "                    sents_A.append(np1 + \" is \" + n + \" than \" + np2 + ' . ')\n",
    "                    sents_B.append(np1 + \" is \" + n + \" than \" + np2 + ' . ')\n",
    "                    labels.append('ENTAILMENT')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "open(\"testData/true/s1.comp\", 'w').write(\"\\n\".join([str(x) for x in sents_A]))\n",
    "open(\"testData/true/s2.comp\", 'w').write(\"\\n\".join([str(x) for x in sents_B]))\n",
    "np.savetxt(\"testData/true/labels.comp\", [label2id[x] for x in labels], fmt='%i')\n",
    "\n",
    "print(\"Total: \", len(labels), \"\\n\")\n",
    "\n",
    "N = 5\n",
    "temp = np.random.randint(0, len(labels), N)\n",
    "for i in temp:\n",
    "    print(sents_A[i])\n",
    "    print(sents_B[i])\n",
    "    print(labels[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "#FUTURE\n",
    "# Might be easier to just give Mturkers the _np_ is _\"more\"_ _adj_ _np_ framework and ask to fill?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requiring knowledge of part of speech changes (?)\n",
    "\n",
    "A. verb - noun distinction\n",
    "\n",
    "        You can model the train ; \n",
    "        you can train the model\n",
    "        (NEUTRAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. phrase structure/finding objects (?)\n",
    "\n",
    "        Two men are sitting on the hay making rice ; \n",
    "        Two men are sitting on the rice making hay\n",
    "        (NEUTRAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Symmetric connectives:\n",
    "\n",
    "These are all entailment though - so it's less interesting, i.e. even BOW should get this right if it entails for equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
